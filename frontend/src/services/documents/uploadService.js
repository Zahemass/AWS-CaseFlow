// src/services/documents/uploadService.js
// âœ… Updated version with in-browser PDF extraction + correct S3 key handling + single /documents POST

import { uploadData, getUrl, remove } from 'aws-amplify/storage';
import { fetchAuthSession } from 'aws-amplify/auth';
import { S3_CONFIG } from '@/config/aws.config';
import apiClient from '@/services/api/apiClient';
import { ENDPOINTS } from '@/services/api/endpoints';
import { extractPdfTextInBrowser } from './pdfExtract.browser'; // ğŸ‘ˆ helper for PDF text extraction

// ---------------------------
// ğŸ”¹ Helper: generate a unique documentId
// ---------------------------
function makeId() {
  if (crypto?.randomUUID) return crypto.randomUUID();
  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {
    const r = (Math.random() * 16) | 0,
      v = c === 'x' ? r : (r & 0x3) | 0x8;
    return v.toString(16);
  });
}

// ---------------------------
// ğŸ”¹ Check AWS Amplify connection (debug helper)
// ---------------------------
export const checkAWSConnection = async () => {
  try {
    console.log('ğŸŸ¡ Checking AWS Amplify connection...');
    console.log('S3 bucket (env):', import.meta.env.VITE_AWS_S3_BUCKET);
    console.log('S3 config bucket:', S3_CONFIG.bucket);
    console.log('S3 region:', S3_CONFIG.region);

    const session = await fetchAuthSession();
    const creds = session.credentials;

    if (creds?.accessKeyId) {
      console.log('âœ… AWS Connected: Credentials loaded successfully.');
      console.log('ğŸ”‘ AccessKeyId:', creds.accessKeyId.slice(0, 8) + '...');
      console.log('ğŸ‘¤ IdentityId:', session.identityId);
      console.log('ğŸŒ Region:', S3_CONFIG.region);
    } else {
      console.warn('âš ï¸ AWS credentials not found. Possibly not signed in yet.');
    }
  } catch (err) {
    console.error('âŒ AWS connection check failed:', err);
  }
};

// ---------------------------
// ğŸ”¹ Main Upload Function
// ---------------------------
export const uploadFile = async (file, keyPrefix = 'uploads/', caseId = 'GENERAL') => {
  try {
    await checkAWSConnection();

    // STEP 1ï¸âƒ£ â†’ Generate unique documentId
    const documentId = makeId();
    console.log('ğŸ†” Generated documentId:', documentId);

    // STEP 2ï¸âƒ£ â†’ Extract PDF text (if applicable)
    let extractedText = '';
    let pagesCount = 0;

    if (file.type === 'application/pdf') {
      console.log('ğŸ“˜ Extracting text from PDF before upload...');
      try {
        const { text, pages } = await extractPdfTextInBrowser(file);
        extractedText = text;
        pagesCount = pages;
        console.log(`âœ… Extracted ${text.length} chars from ${pages} pages.`);
      } catch (extractErr) {
        console.warn('âš ï¸ PDF extraction failed:', extractErr);
      }
    } else {
      console.log(`â„¹ï¸ Skipping text extraction (file type: ${file.type})`);
    }

    // STEP 3ï¸âƒ£ â†’ Upload file to S3
    const amplifyKey = `${keyPrefix}${Date.now()}-${file.name}`;
    console.log(`ğŸ“¤ Uploading to S3 â†’ bucket: ${S3_CONFIG.bucket}, key: ${amplifyKey}`);

    const result = await uploadData({
      key: amplifyKey,
      data: file,
      options: {
        contentType: file.type,
        progressCallback(progress) {
          const percent = Math.round((progress.transferredBytes / progress.totalBytes) * 100);
          console.log(`ğŸ“¶ Upload progress: ${percent}%`);
        },
      },
    }).result;

    console.log('âœ… S3 upload successful:', result);

    // ğŸŸ¢ FIX â€” Amplify already stores under "public/"
    const actualS3Key = amplifyKey;
    console.log(`ğŸ“ Actual stored S3 key: ${actualS3Key}`);

    // STEP 4ï¸âƒ£ â†’ Notify backend (/documents)
    const payload = {
      documentId,
      title: file.name,
      s3Key: actualS3Key, // âœ… No manual "public/" prefix
      caseId,
      extractedText,
      pagesCount,
    };

    console.log('ğŸ“¨ Sending to backend /documents:', payload);
    const response = await apiClient.post(ENDPOINTS.DOCUMENTS.BASE, payload);
    console.log('ğŸª£ Saved in DynamoDB (documents + extracted):', response.data);

    return {
      documentId,
      key: actualS3Key,
      amplifyKey,
      caseId,
      ...result,
    };
  } catch (error) {
    console.error('âŒ Upload failed:', error);
    throw error;
  }
};

// ---------------------------
// ğŸ”¹ Get signed file URL
// ---------------------------
export const getFileUrl = async (key) => {
  try {
    // Amplify adds "public/" automatically, so we strip it when generating URL
    const amplifyKey = key.startsWith('public/') ? key.substring(7) : key;
    console.log(`ğŸ”— Fetching signed URL for: ${amplifyKey}`);

    const { url } = await getUrl({
      key: amplifyKey,
      options: { bucket: S3_CONFIG.bucket, expiresIn: 3600 },
    });

    console.log('âœ… Signed URL generated:', url);
    return url;
  } catch (error) {
    console.error('âŒ Failed to fetch file URL:', error);
    throw error;
  }
};

// ---------------------------
// ğŸ”¹ Delete file from S3
// ---------------------------
export const deleteFile = async (key) => {
  try {
    // Same logic: remove "public/" prefix if exists
    const amplifyKey = key.startsWith('public/') ? key.substring(7) : key;
    console.log(`ğŸ—‘ï¸ Deleting file from bucket: ${S3_CONFIG.bucket}`);

    await remove({
      key: amplifyKey,
      options: { bucket: S3_CONFIG.bucket },
    });

    console.log('âœ… File deleted successfully:', key);
  } catch (error) {
    console.error('âŒ File deletion failed:', error);
    throw error;
  }
};

// ---------------------------
// ğŸ”¹ Backward compatibility alias
// ---------------------------
export const uploadToS3 = uploadFile;
